---
title: "DACON PROJECT"
subtitle: "동서발전 태양광 발전량 예측 AI 경진대회"
date: '`r Sys.Date()`'
output: 
  html_document:
    toc: true
    toc_float: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r, message = FALSE, warning=FALSE}
library(lubridate)
library(tidymodels)
library(modeltime)
library(modeltime)
library(timetk)
library(tidyverse)
```

## Overviews

DACON "동서발전 태양광 발전량 예측 AI 경진대회" (이하 동서발전)에
따르면, 태양광 발전은 매일 기상 상황과 계절에 따른 일사량의 영향을
받는다. 따라서 기상 상황과 계절을 바탕으로 일사량을 예측할 수 있다면,
태양광 발전량에 대한 예측이 가능하다는 것이다.

이 발표자료에서는 기상예보 오픈데이터(이하 기상예보)를 이용하여 일사량을
예측하는 모델을 `{tidymodel}`로 구축하는 것을 목적으로 한다. 구체적으로
외부 데이터인 기상예보 데이터를 바탕으로 `train` 데이터의 일사량을
예측하는 모델을 학습하고, 이후 `test`의 일사량을 기상예보 데이터로
예측하는 것을 목적으로 한다.

최종적으로는 이 예측된 일사량이 `test`에 포함되어 발전량을 예측에 활용될
것을 기대한다.

## Import the data

`energy.csv`는 데이콘에서 제공하는 발전소별 발전량 데이터이다.
`energy.csv`는 2018년 3월 1일 오전 1시부터 2021년 2월 1일 0시까지를
다루고 있다.

```{r}
energy <- read.csv("energy/energy.csv") %>% 
  mutate(time = ymd_hms(time)) %>% arrange(time)
summary(energy$time)
```

### 당진 기상예보 데이터

아래 당진의 기상예보 데이터는 김종헌 님의 코드를 기준으로 전처리하여
머지한 것이다. 우선, 외부 데이터(연도별)로부터 2015년부터 2021년 2월
1일까지의 당진의 기상예보 데이터를 머지하였다.

```{r}
dangjin <- read.csv("energy/OBS_2015.csv") %>%
  bind_rows(read.csv("energy/OBS_2016.csv")) %>% 
  bind_rows(read.csv("energy/OBS_2017.csv")) %>% 
  bind_rows(read.csv("energy/OBS_2018.csv")) %>% 
  bind_rows(read.csv("energy/OBS_2019.csv")) %>% 
  bind_rows(read.csv("energy/OBS_2020.csv")) %>% 
  bind_rows(read.csv("energy/OBS_2021.csv")) %>% 
  select(-c(1:2)) %>% 
  select(time = 1, 일사=12, 기온=2, 강수=3, 풍속=4, 풍향=5, 습도=6, 증기압=7,
         이슬점=8, 기압=9, 해면기압=10, 일조=11, 
         적설=13, 전운량=14, 운형=15, 시정=16, 지면온도=17) %>% 
    as_tibble() %>% mutate(time=ymd_hm(time)) %>% select(-c(운형, 적설)) %>% 
    right_join(data.frame(time=seq(as.POSIXct("2015-01-01 01:00", tz="gmt"), 
                                   as.POSIXct("2021-02-01 00:00", tz="gmt"), 
                                   by="hour"))) %>%
  mutate(일사 = if_else(is.na(일사), 0, 일사), 
         강수 = if_else(is.na(강수), 0, 강수))
head(dangjin, n = 50)

```

### 울산 기상예측데이터

```{r}
ulsan <- read.csv("energy/OBS_ulsan2015.csv") %>% 
  bind_rows(read.csv("energy/OBS_ulsan2016.csv")) %>% 
  bind_rows(read.csv("energy/OBS_ulsan2017.csv")) %>% 
  bind_rows(read.csv("energy/OBS_ulsan2018.csv")) %>% 
  bind_rows(read.csv("energy/OBS_ulsan2019.csv")) %>% 
  bind_rows(read.csv("energy/OBS_ulsan2020.csv")) %>% 
  bind_rows(read.csv("energy/OBS_ulsan2021.csv")) %>% 
  select(-c(1:2)) %>% 
  select(time=1, 일사=12, 기온=2, 강수=3, 풍속=4, 풍향=5, 습도=6, 증기압=7,
         이슬점=8, 기압=9, 해면기압=10, 일조=11, 
         적설=13, 전운량=14, 운형=15, 시정=16, 지면온도=17) %>% 
    as_tibble() %>% mutate(time=ymd_hm(time)) %>% select(-c(운형, 적설)) %>% 
    right_join(data.frame(time=seq(as.POSIXct("2015-01-01 01:00", tz="gmt"), 
                                   as.POSIXct("2021-02-01 00:00", tz="gmt"), 
                                   by="hour"))) %>%
  mutate(일사 = if_else(is.na(일사), 0, 일사), 
         강수 = if_else(is.na(강수), 0, 강수))
head(ulsan, n = 50)
```

여기서의 기대는 2015년 1월 1일부터 2018년 2월 28일까지의 데이터가 일종의
일사량을 위한 `train` 데이터로, 그리고 2018년 3월 1일부터 2021년 2월
1일까지의 데이터가 `test` 데이터로써 예측 일사량을 제공하는 모델링을
구축하는 것이다.

두 지역(당진, 울산)의 지역적 차이 등을 고려하여 두 표본을 나누어 모델을
구축한다. 먼저 각각의 머지한 데이터로부터 일사량을 예측하는데 필요할
것으로 기대되는 변수들을 상관관계에 입각하여 추출해보고자 한다.

```{r}
library(PerformanceAnalytics)
chart.Correlation(dangjin %>% select(-1), histogram=TRUE, pch=19)
chart.Correlation(ulsan %>% select(-1), histogram=TRUE, pch=19)
```

구동에 조금 시간이 걸리기는 하지만 일단 당진(`dangjin`)에 포함된
변수들이 일사량과 갖는 관계를 살펴보면 주요한 상관성을 가지는 변수는
크게 다음과 같다. 이는 이전에 김종헌 님이 제시하였던 {일사량, 습도,
(시정, 전운량), (강수, 풍속, 풍향)}과 크게 다르지 않다. 다만 울산의 경우에는 
시정이 일사량과 거의 관계를 가지지 않는 것으로 나타났다.

| 변수     | 당진(서산) | 울산  |
|----------|------------|-------|
| 기온     | 0.35       | 0.33  |
| 풍속     | 0.42       | 0.31  |
| 풍향     | 0.32       | 0.25  |
| 습도     | -0.61      | -0.49 |
| 일조     | 0.73       | 0.74  |
| 시정     | 0.46       |       |
| 지면온도 | 0.54       | 0.57  |

그리고 일조량과 일사량은 개념 상 굉장히 높은 상관관계를 가질 수밖에
없다. 왜냐하면 일사량은 일조량에 포함된 것이기 때문이다.

-   일조량: 일정한 물체의 표면이나 지표면에 비치는 햇볕의 양

-   일사량: 구름이나 안개 등의 방해 없이 지구를 향해 비춰지는 빛의 양

그러나 일조량보다는 일사량이 중요하다. 일사량이 낮 시간 동안에
태양광모듈에 도달하여 이르는 시간이 태양광발전에 있어 가장 중요한
요인이기 때문이다.

따라서 일조량은 일사량과 개념적으로든 실제적으로든 굉장히 높은
상관관계를 가질 수 밖에 없다는 점에서 일종의 유사한 개념을 측정하기 위한
조금 다른 조작지표라 볼 수 있다. 따라서 여기에서는 일조를 제외하기로
하였다.

유의미할 것으로 기대되는 변수들은 따라서 {기온, 풍속, 풍향, 습도, 시정(울산 제외),
지면온도}로 추려진다.

```{r}
names(dangjin)
dangjin_set <- dangjin %>% select(1:3, 5:7, 14:15)
ulsan_set <- ulsan %>% select(1:3, 5:7, 15)
```

그리고 추려진 데이터셋으로 상관관계를 다시 한 번 살펴보자. 상관관계는 어차피 
양변량 관계이므로 달라지지는 않지만 변수의 수가 줄어 한눈에 보기는 편하다.

```{r}
chart.Correlation(dangjin_set %>% select(-1), histogram=TRUE, pch=19)
chart.Correlation(ulsan_set %>% select(-1), histogram=TRUE, pch=19)
```

## 당진 기상의 Train and Test

```{r}
dangjin_train <- dangjin_set %>% 
  dplyr::filter(time <= ymd("2018-02-28")) %>% 
  arrange(time)
dangjin_test <- dangjin_set %>% 
  dplyr::filter(time > ymd("2018-02-28")) %>% 
  arrange(time) %>% mutate(일사 = NA_real_)
dangjin_all <- bind_rows(dangjin_train, dangjin_test)
glimpse(dangjin_all)
```

## Recipe
당진 기상예보에서 일사량을 예측하기 위한 모델링 전처리를 위해 레시피를 구성했다.
레시피는 일단 숫자형 변수들을 표준화하고, 결측치는 변수 분포에 따라 중위값으로
대체하였다. 

```{r}
dangjin_set %>% tidyr::gather(var, value) %>% dplyr::filter(!var == "time") %>%
  ggplot(aes(value)) + 
  geom_histogram(aes(y = ..density..), color = "black", fill = "white") + 
  geom_density() + 
  facet_wrap(~var, scales = "free") + 
  labs(x = "", y = "") + 
  theme_bw()
# 결측치가 있을 시
# median으로 채우는 것으로 나아 보임.

naniar::gg_miss_var(dangjin_set)

```

[timetk](https://business-science.github.io/timetk/articles/TK03_Forecasting_Using_Time_Series_Signature.html)에 따라서 tidymodels로 timeseries를 구현해보고자 하였으나 실패하였다.

1. Error in storage.mode(xd) <- "double" : 
  '<ec><9b><94>'에서 유효하지 않은 멀티바이트 문자열이 있습니다 라는 에러가 나타남.
  
2. 아래에는 그냥 time을 제외하고 돌렸지만, modeltimes를 이용할 경우 `time_series_split`라는
   함수를 이용해서 `test`와 `train`을 나누어주는데, 그 이후 recipe 처리 과정에서
   뭔가 문제가 있는 듯 함.
   

```{r}
sunpower_recipe <- 
    recipe(일사 ~ ., data = dangjin_all) %>% 
    step_rm(time) %>%
    step_medianimpute(시정, 지면온도, 풍향, 풍속, 습도, 기온) %>%    
    step_zv(all_predictors()) %>% 
    step_normalize(all_predictors())
sunpower_prep<- prep(sunpower_recipe, training = dangjin_all) 
sunpower_baked <- bake(sunpower_prep, 
                       new_data = dangjin_all)
test_date <- dangjin_test %>% select(1)

# Train and Test 분할
dj_train_index <- seq_len(nrow(dangjin_train))
dangjin_train2 <- sunpower_baked[dj_train_index,]
dangjin_test2 <- sunpower_baked[-dj_train_index,]

# linear regression
dj_lm_model <-
    linear_reg() %>%
    set_mode("regression") %>%
    set_engine("lm")

lm.mod_dj <- 
    dj_lm_model %>% 
    fit(일사 ~ ., data = dangjin_train2)

## XGBoost

xgb_spec <- boost_tree(
    trees = 1000, # 앙상블에 포함되는 tree의 수 
    tree_depth = tune(), # 얼마만큼 노드를 split할건지 
    min_n = tune(), # 노드를 분할하는데 필요한 최소 데이터의 수
    loss_reduction = tune(), # 노드 분할에 필요한 loss의 감소량 
    sample_size = tune(), # The amount of data exposed to the fitting routine
    mtry = tune(), # The number of predictors that will be randomly sampled at each split when creating the tree models. 
    learn_rate = tune() 
) %>% 
    set_engine('xgboost', objective = "reg:squarederror") %>% 
    set_mode('regression')

params <- parameters(xgb_spec) %>% 
    finalize(dangjin_train2)

xgb_wf <- workflow() %>% 
    add_formula(일사~.) %>% 
    add_model(xgb_spec)

set.seed(2021)
vb_folds <- vfold_cv(dangjin_train2, v = 5, strata = 일사)

doParallel::registerDoParallel()
xgb_res <- tune_bayes(
    object = xgb_wf, # recipe, formula를 지정해준 workflow 
    resamples = vb_folds, 
    param_info = params, 
    iter = 30, 
    metrics = metric_set(rmse), 
    initial = 10, 
    control = control_bayes(
        verbose = TRUE, 
        no_improve = 10, 
        seed = 123) 
)

best_param <- select_best(xgb_res, 'rmse')

final_xgb <- finalize_workflow(xgb_wf, best_param)

final_model <- finalize_model(xgb_spec, best_param) 

final_workflow <- xgb_wf %>% update_model(final_model)

xgb_fit <- fit(final_workflow, data = train2)


pred_xgb <- 
    predict(xgb_fit, dangjin_test2) %>% 
    mutate(modelo = "XGBoost")
pred_xgb %>% head()

pred_xgb$.pred <- exp(pred_xgb$.pred)-1
```

## Prediction

```{r}
predict.dj <- predict(lm.mod_dj, new_data = dangjin_test2)
predict.df.check <- predict.dj %>% rowid_to_column()
actual.dj <- dangjin_set %>% 
  dplyr::filter(time > ymd("2018-02-28")) %>% 
  arrange(time) %>% select(1:2) %>% rowid_to_column()

check <- left_join(actual.dj, predict.df.check)
check %>% 
  ggplot(aes(x = 일사, y = .pred)) + geom_point() + geom_abline(color = "red")
```

## 중간 결론

1. 너무나도 당연하게, 시계열적 특성을 고려하지 않은 `lm` 엔진을 활용한 예측은 실제 예측과 너무 다르게 나타남.

   a. 예측이 잘 되었다면 두 변수의 관계가 abline선으로 수렴할텐데, 그렇지 않음.
   
   b. interpolation과 extrapolation의 문제가 당연히 존재할 것으로 보임.

2. 본인이 timeseries 분석을 해본 적이 없어 분석에 어려움이 있었지만, 이전에 종헌님이 사용하신 패키지 외에
   tidymodels도 timeseries + machine learning 패키지를 제공하고 있음 (위의 링크).
   
   그런데 상대적으로 multivariate time-series (다른 변수들과 시간의 영향을 함께 고려한) 분석으로 예측을
   하고자 할 때, 참고할만한 자료가 부족함. (한 번 만들어보면 어떨지?)
   
3. 적어도 univariate 한 측면에서 제공되는 자료들을 볼 때는 이해가 쉽고 코드가 깔끔해보였음.
   
